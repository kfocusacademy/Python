{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "50937e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights [ 0.13623124 -0.11596551  0.1357645 ], bias 1.4920000000000002: Cost 5611.8: Iterations 0\n",
      "Weights [ 2.7905224  -1.36510854  2.63200445], bias 64.90444950764638: Cost 99.17487857803364: Iterations 100\n",
      "Weights [ 3.1512136  -0.76651773  2.86369872], bias 73.3141803995489: Cost 2.4669657327033163: Iterations 200\n",
      "Weights [ 3.40492441 -0.32794548  3.03055305], bias 74.42947517562742: Cost 0.4873368214321542: Iterations 300\n",
      "Weights [ 3.58564204 -0.00963224  3.15499514], bias 74.57738507352265: Cost 0.3061043611292139: Iterations 400\n",
      "Weights [3.71349893 0.22155084 3.2487227 ], bias 74.59700081849391: Cost 0.22594369205466638: Iterations 500\n",
      "Weights [3.80306626 0.38961522 3.3201965 ], bias 74.5996022498806: Cost 0.18400196770123806: Iterations 600\n",
      "Weights [3.8648995  0.51195509 3.37554558], bias 74.59994725055583: Cost 0.16185607937114893: Iterations 700\n",
      "Weights [3.90664513 0.60117097 3.41920989], bias 74.59999300439215: Cost 0.1500941941723734: Iterations 800\n",
      "Weights [3.93384237 0.66639083 3.4544058 ], bias 74.59999907224558: Cost 0.1437817564164788: Iterations 900\n",
      "weights [-6.24819974  2.82842712 15.55634919], bias 74.6\n",
      "\n",
      "Gradient Descent weights: [3.9503791  0.71381782 3.48319709]\n",
      "Gradient Descent bias: 74.59999987445065\n",
      "\n",
      "LinearRegression weights: [-6.24819974  2.82842712 15.55634919]\n",
      "LinearRegression bias: 74.6\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Sample Data\n",
    "X1_study_hrs = np.array([10,15,8,12,6]) \n",
    "X2_sleep_hrs = np.array([7,6,8,5,9]) \n",
    "X3_practice_tests = np.array([2,4,1,3,0]) \n",
    "y_score = np.array([75,85,70,78,65])\n",
    "\n",
    "n = len(y_score)\n",
    "# Prepare raw data\n",
    "X  = np.column_stack((X1_study_hrs, X2_sleep_hrs, X3_practice_tests))\n",
    "# Normalize features\n",
    "X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "# Initialize weights and bias \n",
    "weights = np.zeros(3)\n",
    "bias = 0\n",
    "learning_rate = 0.01\n",
    "iterations = 1000\n",
    "\n",
    "# Storing History for animated graph \n",
    "planes = []\n",
    "\n",
    "for i in range(iterations):\n",
    "    y_pred = np.dot(X,weights) + bias \n",
    "    error = y_score - y_pred    \n",
    "    cost = np.mean (error ** 2)\n",
    "    \n",
    "    # Gradients \n",
    "    # By transposing X, you flip the matrix so each feature becomes a row, \n",
    "    # and you can dot it with the error vector to see how much that feature is responsible \n",
    "    # for the error across all students.\n",
    "    w_grad = -(2/n) * np.dot(X.T,error)\n",
    "    b_grad = -(2/n) * np.sum(error)\n",
    "    \n",
    "    # Update \n",
    "    weights -= learning_rate*w_grad \n",
    "    bias -= learning_rate*b_grad \n",
    "    \n",
    "    if (i%100==0):\n",
    "        print(\"Weights {}, bias {}: Cost {}: Iterations {}\".format(weights,bias,cost,i))\n",
    "        \n",
    "    # Store Place\n",
    "    planes.append((weights.copy(),bias))\n",
    "\n",
    "\n",
    "    \n",
    "# To compare model values with linear regression\n",
    "# Find W1,W2,W3 using linear regression \n",
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression()\n",
    "#X = np.column_stack((X1_study_hrs,X2_sleep_hrs,X3_practice_tests))\n",
    "reg.fit(X,y_score)\n",
    "print(\"weights {}, bias {}\".format(reg.coef_, reg.intercept_))\n",
    "print(\"\\nGradient Descent weights:\", weights)\n",
    "print(\"Gradient Descent bias:\", bias)\n",
    "\n",
    "print(\"\\nLinearRegression weights:\", reg.coef_)\n",
    "print(\"LinearRegression bias:\", reg.intercept_)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "455fed70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.06401844  0.          0.        ]\n",
      " [ 1.53644256 -0.70710678  1.41421356]\n",
      " [-0.70420284  0.70710678 -0.70710678]\n",
      " [ 0.57616596 -1.41421356  0.70710678]\n",
      " [-1.34438724  1.41421356 -1.41421356]]\n",
      "weights [-6.24819974  2.82842712 15.55634919], bias 74.6\n"
     ]
    }
   ],
   "source": [
    "# Find W1,W2,W3 using linear regression \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X = np.array([\n",
    "    [10, 7, 2],\n",
    "    [15, 6, 4],\n",
    "    [8, 8, 1],\n",
    "    [12, 5, 3],\n",
    "    [6, 9, 0]\n",
    "])\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "y_score = np.array([75,85,70,78,65])\n",
    "\n",
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression()\n",
    "#X = np.column_stack((X1_study_hrs,X2_sleep_hrs,X3_practice_tests))\n",
    "print(X_scaled)\n",
    "reg.fit(X_scaled,y_score)\n",
    "print(\"weights {}, bias {}\".format(reg.coef_, reg.intercept_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e200da7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "10*-2 + 7*2 + 2*11 + 58.99 = 75.99\n",
    "\n",
    "# 3.93384237 0.66639083 3.4544058 ], Bias=74.60\n",
    "10*3.93 + 7*0.666 + 2*3.45 + 74.60 = 75.998"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
